{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), f'E:\\Project_CSC\\Ml\\ml_everyFeature\\models_mlp_32_16\\mlp_model_{feature}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "input_data = input_data.iloc[:, :].values\n",
    "# Data preprocessing\n",
    "scaler = StandardScaler()\n",
    "input_data = scaler.fit_transform(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算各类损失\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, max_error, mean_absolute_percentage_error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "explained_variance = explained_variance_score(y_test, predictions)\n",
    "max_err = max_error(y_test, predictions)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用plt可视化预测结果\n",
    "def visualize_predictions(y_test, predictions, filename):\n",
    "    fig = plt.figure()\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    print(f\"Mean Absolute Error on Test Set: {mae}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Subfigure 1: Predicted values vs. true values\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_test, predictions, color='blue')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title('Predictions vs. True Values')\n",
    "\n",
    "    # Subfigure 2: Real and predicted values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    plt.plot(y_test, color='red', label='True Values')\n",
    "    plt.plot(predictions, color='blue', label='Predictions')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('True Values vs. Predictions')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在图像上绘制一条 y=x的直线\n",
    " # Get the range of the current axis\n",
    "xlim = plt.xlim()\n",
    "ylim = plt.ylim()\n",
    "\n",
    "# Choose the larger range of x and y as the endpoint of the line to ensure that the line covers the entire chart\n",
    "max_range = max(xlim[1] - xlim[0], ylim[1] - ylim[0])\n",
    "x_values = np.array([xlim[0], xlim[1]])\n",
    "y_values = x_values\n",
    "plt.plot(x_values, y_values, 'r-', lw=4, label='y=x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算协方差\n",
    "# k为阈值系数\n",
    "from scipy.stats import pearsonr\n",
    "def calculate_correlation(df1, df2, k):\n",
    "    correlated_columns = []\n",
    "    for col1 in df1.columns:\n",
    "        for col2 in df2.columns:\n",
    "            correlation, _ = pearsonr(df1[col1], df2[col2])\n",
    "            if abs(correlation) > k:\n",
    "                correlated_columns.append((col1, col2, correlation))\n",
    "    return correlated_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在一个文件夹下读取所有的某一类型的文件\n",
    "import os\n",
    "def get_excel_files(directory):\n",
    "    excel_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "                excel_files.append(os.path.join(root, file))\n",
    "    return excel_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在excel当中删除指定列名的列， 并重命名列\n",
    "columns_to_drop = ['thresholdSrc', 'thresholdMethod', 'percentile']\n",
    "filtered_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "column_names = filtered_df.columns\n",
    "new_column_names = [tname + \"_\" + col_name for col_name in column_names]\n",
    "filtered_df.columns = new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两张表格进行拼接\n",
    "concatenated_df = pd.concat([concatenated_df, filtered_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除所有符合条件的列\n",
    "columns_to_drop = [col for col in concatenated_df.columns if 'id' in col.lower() and col.lower() != 'all_id']\n",
    "concatenated_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选表格中，每一列为指定内容的所有元组\n",
    "filtered_df = df[(df['thresholdSrc'] == thresholdSrc) & (df['thresholdMethod'] == method) & (df['percentile'] == percentile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得开发时间的年月日信息\n",
    "from datetime import datetime\n",
    "f\"{datetime.now().date():%Y-%m-%d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在一张excel表格中保存多张子表\n",
    "# 创建ExcelWriter对象，指定要保存的Excel文件路径,并添加时间戳\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "with pd.ExcelWriter(f'output_{datetime.now().date():%Y-%m-%d}.xlsx') as writer:\n",
    "    # 将df_whole保存到名为'data{i}_whole'的工作表中\n",
    "    df_whole.to_excel(writer, sheet_name=f'data_whole', index=False)\n",
    "    df_bg.to_excel(writer, sheet_name=f'data_bg', index=False)\n",
    "    df_subSquares.to_excel(writer, sheet_name=f'data_subSquares', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
